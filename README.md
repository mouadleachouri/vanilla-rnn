# README

This is a simple toy implementation of a sequence to sequence vanilla RNN, where
the input and output are of the same size. Inspired by Andrew Ng's Sequence
Models course.

It uses batch gradient with gradient clipping and simple random initialization
for the weights.
